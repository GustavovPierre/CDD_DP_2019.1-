{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Victor Jurdi\n",
    "\n",
    "## Gustavo Pierre\n",
    "\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\gppie\\Downloads\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email Class\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pd.read_excel('spamham2019(1).xlsx')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_texto(ser_orig):\n",
    "    ser = ser_orig.copy()\n",
    "    ser=ser.str.replace('@', ' ')\n",
    "    ser=ser.str.replace(\"'\", ' ')\n",
    "    ser=ser.str.replace('\"', ' ')\n",
    "    ser=ser.str.replace('.', ' ')\n",
    "    ser=ser.str.replace('(', ' ')\n",
    "    ser=ser.str.replace(')', ' ')\n",
    "    ser=ser.str.replace('$', ' ')\n",
    "    ser=ser.str.replace('*', ' ')\n",
    "    ser=ser.str.replace(':', ' ')\n",
    "    ser=ser.str.replace(';', ' ')\n",
    "    ser=ser.str.replace('-', ' ')\n",
    "    ser=ser.str.replace('_', ' ')\n",
    "    ser=ser.str.replace('%', ' ')\n",
    "    ser=ser.str.replace('/', ' ')\n",
    "    ser=ser.str.replace('!', ' ')\n",
    "    ser=ser.str.replace('?', ' ')\n",
    "    ser=ser.str.replace('[', ' ')\n",
    "    ser=ser.str.replace(']', ' ')\n",
    "    ser=ser.str.replace('{', ' ')\n",
    "    ser=ser.str.replace('}', ' ')\n",
    "    ser=ser.str.replace('+', ' ')\n",
    "    ser=ser.str.replace('>', ' ')\n",
    "    ser=ser.str.replace('<', ' ')\n",
    "    ser=ser.str.replace('^', ' ')\n",
    "    ser=ser.str.replace('~', ' ')  \n",
    "    ser=ser.str.replace('=', ' ')\n",
    "    ser=ser.str.replace('#', ' ')\n",
    "    ser=ser.str.replace('+', ' ')\n",
    "    ser=ser.str.replace('•', ' ')\n",
    "    ser=ser.str.replace(',', ' ')\n",
    "\n",
    "\n",
    "    #Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "    ser=ser.str.replace(' a ', ' ')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    return ser\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point  crazy   Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar    Joking wif u oni</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 wkly comp to win FA Cup final ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor    U c already then say</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don t think he goes to usf  he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it s been 3 week s n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me  ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request  Melle Melle  Oru Minnamin...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER   As valued network customer you have b...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more  U R entitle...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email Class\n",
       "0  Go until jurong point  crazy   Available only ...   ham\n",
       "1                      Ok lar    Joking wif u oni      ham\n",
       "2  Free entry in 2 wkly comp to win FA Cup final ...  spam\n",
       "3  U dun say so early hor    U c already then say      ham\n",
       "4  Nah I don t think he goes to usf  he lives aro...   ham\n",
       "5  FreeMsg Hey there darling it s been 3 week s n...  spam\n",
       "6  Even my brother is not like to speak with me  ...   ham\n",
       "7  As per your request  Melle Melle  Oru Minnamin...   ham\n",
       "8  WINNER   As valued network customer you have b...  spam\n",
       "9  Had your mobile 11 months or more  U R entitle...  spam"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"Email\"] = limpa_texto(x[\"Email\"])\n",
    "x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest = train_test_split(x, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam=xTrain[\"Email\"][xTrain.Class==\"spam\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06664273749700886"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps=(557/8358)\n",
    "Ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333572625029911"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ph=1-Ps\n",
    "Ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P(SPAM)=0,06664\n",
    "\n",
    "## P(HAM)=0,93335\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>Aight should I just plan to come up later toni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Was the farm open</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>I sent my scores to sophas and i had to do sec...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>Was gr8 to see that message  So when r u leavi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>In that case I guess I ll see you at campus lodge</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>Nothing will ever be easy  But don t be lookin...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>If you were are free i can give  Otherwise nal...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>I wnt to buy BMW car urgently  its vry urgent ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>Dont pack what you can buy at any store like c...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>I can take you at like noon</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class\n",
       "4456  Aight should I just plan to come up later toni...   ham\n",
       "690                                  Was the farm open    ham\n",
       "944   I sent my scores to sophas and i had to do sec...   ham\n",
       "3768  Was gr8 to see that message  So when r u leavi...   ham\n",
       "1189  In that case I guess I ll see you at campus lodge   ham\n",
       "4437  Nothing will ever be easy  But don t be lookin...   ham\n",
       "3587  If you were are free i can give  Otherwise nal...   ham\n",
       "1982  I wnt to buy BMW car urgently  its vry urgent ...   ham\n",
       "2038  Dont pack what you can buy at any store like c...   ham\n",
       "2078                        I can take you at like noon   ham"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words=[]\n",
    "for r in spam:\n",
    "    for b in r.split():\n",
    "        spam_words.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham=xTrain['Email'][xTrain.Class=='ham']\n",
    "ham_words=[]\n",
    "for i in ham:\n",
    "    for e in i.split():\n",
    "        ham_words.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras = []\n",
    "#SEM REPETIÇÃO\n",
    "for e in spam_words:\n",
    "    if e not in todas_palavras:\n",
    "        todas_palavras.append(e)\n",
    "for u in ham_words:\n",
    "    if u not in todas_palavras:\n",
    "        todas_palavras.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctodas_palavras = []\n",
    "#COM REPETIÇÃO\n",
    "for e in spam_words:\n",
    "    Ctodas_palavras.append(e)\n",
    "for u in ham_words:\n",
    "    Ctodas_palavras.append(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.Series(spam_words)\n",
    "prob_spam = len(s)/(len(spam_words)+len(ham_words))\n",
    "#s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = s.value_counts()\n",
    "\n",
    "s2 = s1.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21222369851431333"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEM REPETIÇÃO\n",
    "spam_s_repeticao = []\n",
    "for e in spam_words:\n",
    "    if e not in spam_s_repeticao:\n",
    "        spam_s_repeticao.append(e)\n",
    "ham_s_repeticao = []\n",
    "for e in ham_words:\n",
    "    if e not in ham_s_repeticao:\n",
    "        ham_s_repeticao.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=pd.Series(ham_words)\n",
    "prob_ham= len(h)/(len(spam_words)+len(ham_words))\n",
    "#h.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.value_counts()\n",
    "h2 = h1.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrases=[]\\nfor e in xTest[\"Email\"]:\\n    linha=e.split()\\n    frases.append(linha)\\n\\n        \\n        \\n    \\nfrases\\nTeste_dic={}\\ni=0\\nfor e in frases:\\n    \\n    Teste_dic[i]=e\\n    i+=1\\n\\nTeste_dic\\n'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "frases=[]\n",
    "for e in xTest[\"Email\"]:\n",
    "    linha=e.split()\n",
    "    frases.append(linha)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "frases\n",
    "Teste_dic={}\n",
    "i=0\n",
    "for e in frases:\n",
    "    \n",
    "    Teste_dic[i]=e\n",
    "    i+=1\n",
    "\n",
    "Teste_dic\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def's que calculam a P(word|SPAM) e P(word|HAM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#palavra = input()\n",
    "\n",
    "def p_palavra_spam(palavra):\n",
    "    if palavra in todas_palavras:\n",
    "        if palavra in spam_s_repeticao and palavra in ham_s_repeticao:\n",
    "            prob_palavra_spam = (s2[palavra]+1) / (len(spam_words)+len(Ctodas_palavras))\n",
    "        if palavra in spam_s_repeticao and palavra not in ham_s_repeticao:\n",
    "            prob_palavra_spam = (s2[palavra]+1) / (len(spam_words)+len(Ctodas_palavras))\n",
    "        if palavra not in spam_s_repeticao and palavra in ham_s_repeticao:\n",
    "            prob_palavra_spam = 1 / (len(spam_words)+len(Ctodas_palavras))\n",
    "            \n",
    "\n",
    "    else:\n",
    "        prob_palavra_spam = 1 / (len(spam_words)+len(Ctodas_palavras))\n",
    "        \n",
    "    return prob_palavra_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_palavra_ham(palavra):\n",
    "    if palavra in todas_palavras:\n",
    "        if palavra in spam_s_repeticao and palavra in ham_s_repeticao:\n",
    "            prob_palavra_ham = (h2[palavra]+1) / (len(ham_words)+len(Ctodas_palavras))\n",
    "        if palavra in spam_s_repeticao and palavra not in ham_s_repeticao:\n",
    "            prob_palavra_ham = 1 / (len(ham_words)+len(Ctodas_palavras))\n",
    "        if palavra not in spam_s_repeticao and palavra in ham_s_repeticao:\n",
    "            prob_palavra_ham = (h2[palavra]+1) / (len(ham_words)+len(Ctodas_palavras))\n",
    "\n",
    "\n",
    "    else:\n",
    "        prob_palavra_ham = 1 / (len(ham_words)+len(Ctodas_palavras))\n",
    "\n",
    "    return prob_palavra_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def que calcula a P(HAM|MSG) e P(SPAM|MSG):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_frase(emails):\n",
    "    ps=1\n",
    "    ph=1\n",
    "    listaa=[]\n",
    "    \n",
    "    for email in emails:\n",
    "        ps = 1\n",
    "        ph = 1\n",
    "        for word in email.split(\" \"):\n",
    "            #print(word)\n",
    "            \n",
    "            o=p_palavra_spam(word)\n",
    "            y=p_palavra_ham(word)\n",
    "            \n",
    "            ps = ps*o\n",
    "            ph = ph*y\n",
    "\n",
    "        psa=ps*prob_spam\n",
    "        pha=ph*prob_ham\n",
    "        if pha>psa:\n",
    "            listaa.append('ham')\n",
    "        elif psa>pha:\n",
    "            listaa.append('spam')\n",
    "        elif ps == ph:\n",
    "            listaa.append(\"igual\")\n",
    "\n",
    "    return listaa    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = prob_frase(xTest[\"Email\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xTest[\"Email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>Aight should I just plan to come up later toni...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Was the farm open</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>I sent my scores to sophas and i had to do sec...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>Was gr8 to see that message  So when r u leavi...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>In that case I guess I ll see you at campus lodge</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Email Class Classificador\n",
       "4456  Aight should I just plan to come up later toni...   ham          spam\n",
       "690                                  Was the farm open    ham          spam\n",
       "944   I sent my scores to sophas and i had to do sec...   ham          spam\n",
       "3768  Was gr8 to see that message  So when r u leavi...   ham          spam\n",
       "1189  In that case I guess I ll see you at campus lodge   ham          spam"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest[\"Classificador\"]=x\n",
    "xTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xTest[\"Classificador\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contando acertos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349 44\n",
      "P de acerto: 96.8413496051687%\n",
      "P de erro: 3.1586503948312994%\n"
     ]
    }
   ],
   "source": [
    "acertos=0\n",
    "erros=0\n",
    "w = []\n",
    "i=0\n",
    "    \n",
    "for t in xTest['Class']:\n",
    "    w.append(t)\n",
    "    \n",
    "while i < len(x):\n",
    "    if x[i]==w[i]:\n",
    "        acertos+=1\n",
    "        i+=1\n",
    "    else:\n",
    "        erros+=1\n",
    "        i+=1\n",
    "        \n",
    "print(acertos,erros)\n",
    "print('P de acerto: {0}%'.format(acertos/1393*100))\n",
    "print('P de erro: {0}%'.format(erros/1393*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Falsos Positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falso_positivo=xTest[(xTest['Class']=='ham')&(xTest['Classificador']==\"spam\")]\n",
    "len(falso_positivo['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.574300071787509"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_fp=len(falso_positivo['Class'])/len(xTest['Class'])\n",
    "prob_fp*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Positivos Verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positivo_verdadeiro=xTest[(xTest['Class']=='spam')&(xTest['Classificador']==\"spam\")]\n",
    "len(positivo_verdadeiro['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.773151471643933"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pv=len(positivo_verdadeiro['Class'])/len(xTest['Class'])\n",
    "prob_pv*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Falsos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falso_negativo=xTest[(xTest['Class']=='spam')&(xTest['Classificador']==\"ham\")]\n",
    "len(falso_negativo['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8664752333094041"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_fn=len(falso_negativo['Class'])/len(xTest['Class'])\n",
    "prob_fn*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negativos Verdadeiros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativo_verdadeiro=xTest[(xTest['Class']=='ham')&(xTest['Classificador']==\"ham\")]\n",
    "len(negativo_verdadeiro['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.06819813352476"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_nv=len(negativo_verdadeiro['Class'])/len(xTest['Class'])\n",
    "prob_nv*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade do classificador acertar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.84134960516869"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pv*100+prob_nv*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre a qualidade do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conferindo as medidas obtidas, o classificador implementado pode ser considerado confiável. Apenas duas categorias foram fornecidas, spam ou ham. Spam no tempo atual chegam em nossas caixas de email em grande abundancia, pois existem muitas correntes e emails repassados para milhares de pessoas. Dessa forma, os spams cada dia estão mais presentes no nosso cotidiano. E que sorte teriamos se algo ja classificasse se o email é um spam ou não, nossa vida seria muito mais facil, nossa caixa de mensagem não ficaria cheia de mensagens indesejadas.\n",
    "\n",
    "\n",
    "O classificador se encontra com uma probabilidade de acerto de aproximadamente 97%, apresentando um grande potencial de melhora. Pela quantidade de \"positivos verdadeiros\" e \"falsos negativos\", vemos que a probabilidade do classificador acertar é alta. Portanto, pode-se concluir que o classificador é bastante preciso.Assim, acreditamos que para aumentar o acerto do classificador, algumas implementações devem ser introduzidas, como: limpar emojis e também aumentar sua base de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos repetir tudo 10 mil vezes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gppie\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-191be2af8c47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mxTrain1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxTest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mspam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxTrain1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mham\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxTrain1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 2102\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 2102\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# Pandas Dataframes and Series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;31m# Cython typed memoryviews internally used in pandas do not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1819\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m         \u001b[1;31m# a single integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1792\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1794\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1795\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m             \u001b[1;31m# re-raise with different error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take\u001b[1;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         new_data = self._data.take(indices,\n\u001b[0;32m   2149\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m                                    verify=True)\n\u001b[0m\u001b[0;32m   2151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   4253\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4255\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\INSPER\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n)\u001b[0m\n\u001b[0;32m   2099\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m         \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2101\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indices are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=pd.read_excel('spamham2019(1).xlsx')\n",
    "x[\"Email\"] = limpa_texto(x[\"Email\"])\n",
    "\n",
    "\n",
    "probabilidades_acerto=[]\n",
    "        \n",
    "for e in range(10001):\n",
    "    xTrain1, xTest1 = train_test_split(x, test_size = 0.25, random_state = 0)\n",
    "    spam=xTrain1\n",
    "    ham=xTrain1\n",
    "   \n",
    "    spam_words=[]\n",
    "    for r in spam:\n",
    "        for b in r.split():\n",
    "            spam_words.append(b)\n",
    "    \n",
    " \n",
    "\n",
    "    ham_words=[]\n",
    "    for i in ham:\n",
    "        for e in i.split():\n",
    "            ham_words.append(e)\n",
    "    \n",
    "    \n",
    "    todas_palavras = []\n",
    "    #SEM REPETIÇÃO\n",
    "    for e in spam_words:\n",
    "        if e not in todas_palavras:\n",
    "            todas_palavras.append(e)\n",
    "    for u in ham_words:\n",
    "        if u not in todas_palavras:\n",
    "            todas_palavras.append(u)\n",
    "    \n",
    "    Ctodas_palavras = []\n",
    "    #COM REPETIÇÃO\n",
    "    for e in spam_words:\n",
    "        Ctodas_palavras.append(e)\n",
    "    for u in ham_words:\n",
    "        Ctodas_palavras.append(u)\n",
    "        \n",
    "    s=pd.Series(spam_words)\n",
    "    prob_spam = len(s)/(len(spam_words)+len(ham_words))\n",
    "    \n",
    "    s1 = s.value_counts()\n",
    "    s2 = s1.to_dict()\n",
    "    \n",
    "    \n",
    "    #SEM REPETIÇÃO\n",
    "    spam_s_repeticao = []\n",
    "    for e in spam_words:\n",
    "        if e not in spam_s_repeticao:\n",
    "            spam_s_repeticao.append(e)\n",
    "    ham_s_repeticao = []\n",
    "    for e in ham_words:\n",
    "        if e not in ham_s_repeticao:\n",
    "            ham_s_repeticao.append(e)\n",
    "    \n",
    "    \n",
    "    h=pd.Series(ham_words)\n",
    "    prob_ham= len(h)/(len(spam_words)+len(ham_words))\n",
    "    \n",
    "    \n",
    "    h1 = h.value_counts()\n",
    "    h2 = h1.to_dict()\n",
    "    \n",
    "    x23 = prob_frase(xTest1.Email)\n",
    "    xTest1[\"Classificador\"]=x23\n",
    "    \n",
    "    falso_positivo=xTest[(xTest1['Class']=='ham')&(xTest1['Classificador']==\"spam\")]\n",
    "    prob_fp=len(falso_positivo['Class'])/len(xTest1['Class'])\n",
    "    \n",
    "    \n",
    "    positivo_verdadeiro=xTest[(xTest1['Class']=='spam')&(xTest1['Classificador']==\"spam\")]\n",
    "    prob_pv=len(positivo_verdadeiro['Class'])/len(xTest1['Class'])\n",
    "    \n",
    "    falso_negativo=xTest[(xTest1['Class']=='spam')&(xTest1['Classificador']==\"ham\")]\n",
    "    prob_fn=len(falso_negativo['Class'])/len(xTest1['Class'])\n",
    "    \n",
    "    negativo_verdadeiro=xTest[(xTest1['Class']=='ham')&(xTest1['Classificador']==\"ham\")]\n",
    "    prob_nv=len(negativo_verdadeiro['Class'])/len(xTest1['Class'])\n",
    "    \n",
    "    \n",
    "    prob_acertar=prob_nv + prob_pv\n",
    "    \n",
    "    probabilidades_acerto.append(prob_acertar)\n",
    "\n",
    "probabilidades_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probabilidades_acerto);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
